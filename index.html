<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml"><head><title>If The Data Will Not Come To The Astronomer (late 2019 version)...</title><meta charset="UTF-8"></meta><meta name="generator" content="Hovercraft! 1.0 http://regebro.github.com/hovercraft"></meta><link rel="stylesheet" href="css/hovercraft.css" media="all"></link><link rel="stylesheet" href="css/impressConsole.css" media="all"></link><link rel="stylesheet" href="css/highlight.css" media="all"></link><link rel="stylesheet" href="css/talk_dark.css" media="screen,projection"></link><script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        showProcessingMessages: false,
        messageStyle: "none",
        TeX : { extensions : ['color.js'] }
      });
    </script></head><body class="impress-not-supported"><div id="impress"><div class="step step-level-1" step="0" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="0" data-y="0" data-z="0"><h1 id="if-the-data-will-not-come-to-the-astronomer-late-2019">If The Data Will Not Come To The Astronomer (late 2019)...</h1><h2 id="tucson-python-meetup-3-december-2019">Tucson Python Meetup, 3 December 2019</h2><h2 id="adam-thornton">Adam Thornton</h2><h2 id="lsst">LSST</h2><p><a href="mailto:athornton@lsst.org">athornton@lsst.org</a></p><img src="images/qr.png"></img></div><div class="step step-level-1" step="1" data-x="4800" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-y="0" data-z="0"><h1 id="this-talk">This Talk</h1><ul><li><a href="https://athornton.github.io/Tucson-Python-Dec-2019">https://athornton.github.io/Tucson-Python-Dec-2019</a></li><li><a href="http://ls.st/gn5">http://ls.st/gn5</a></li></ul><p>Licensed under Creative Commons Attribution 4.0 International license
(CC BY 4.0)</p><img src="images/qr.png"></img></div><div class="step step-level-1" step="2" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="9600" data-y="0" data-z="0"><h1 id="overview">Overview</h1><h2 id="large-synoptic-survey-telescope">Large Synoptic Survey Telescope</h2><h2 id="astronomical-analysis-methodologies">Astronomical Analysis Methodologies</h2><h2 id="interactive-notebook-environment">Interactive Notebook Environment</h2><div class="line-block"><br></br></div></div><div class="step step-level-1" step="3" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="14400" data-y="0" data-z="0"><h1 id="id1">LSST</h1><h2 id="the-large-synoptic-survey-telescope">The Large Synoptic Survey Telescope</h2><p>LSST is funded by the National Science Foundation and the Department of
Energy, as well as a host of other generous donors, public and private.</p></div><div class="step step-level-1" step="4" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="19200" data-y="0" data-z="0"><h1 id="lsst-science-goals">LSST Science Goals</h1><ul><li>LSST will perform a ten-year survey of the Southern sky: whole sky
every three nights at optical and infrared wavelengths.</li><li>Primary goal: detection of faint objects that change between visits:<ul><li>Comprehensive solar system survey.<ul><li>NEOs (&gt; 90% 140m objects by 2040).</li><li>Trans-Neptunian Objects (TNOs).</li></ul></li><li>Milky Way structure and stellar content.</li><li>Transient phenomena at optical wavelengths.<ul><li>AGNs, SN1ae, neutron star/black hole mergers ...</li></ul></li><li>Dark Energy and Dark Matter.<ul><li>Only 4 percent of the mass and energy in the universe is baryonic.</li><li>Is the Hubble Constant the same in every direction?</li></ul></li></ul></li></ul><div class="notes"><p>Just say "objects at every astronomical scale" and list the four.
Don't describe them.</p></div></div><div class="step step-level-1" step="5" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="24000" data-y="0" data-z="0"><h1 id="data-collection-scale">Data Collection Scale</h1><ul><li>About 20 TB a night (roughly entire HST lifetime each week)</li><li>Half an exabyte in the final image collection (DR11).</li><li>Over one trillion photometric measures of celestial sources.</li><li>Reduced catalogue (which most people will use):<ul><li>Smaller than image collection: order of 15 PB.</li><li>Tens of billions of (complex-structured) rows in a database.</li></ul></li></ul></div><div class="step step-level-1" step="6" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="28800" data-y="0" data-z="0"><h1 id="data-scale">Data Scale</h1><ul><li>The data is too big to move easily.</li><li>Hence the need for a standardized compute deployment environment that
facilitates rapid iteration through hypotheses that consider arbitrary
subsets of the data.</li><li>This is at odds with the historical method of astronomical analysis.</li><li>We have an answer for this, but first...what is that data?</li></ul></div><div class="step step-level-1" step="7" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="33600" data-y="0" data-z="0"><h1 id="observations-of-celestial-objects">Observations of Celestial Objects</h1><ul><li>10-40 million AGNs (quasars).</li><li>300,000 supernovae a year.<ul><li>Current detection rate is about 7,000 supernovae per year.</li><li>A supernova explodes in a Milky-Way-scale galaxy once every few
hundred years.</li><li>One goes off somewhere in the observable universe roughly every ten
seconds.</li></ul></li><li>Roughly 20 billion galaxies.</li><li>Roughly 20 billion stars.<ul><li>So everyone could have about three of each.</li></ul></li></ul></div><div class="step step-level-1" step="8" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="38400" data-y="0" data-z="0"><h1 id="lsst-resources">LSST Resources</h1><ul><li><a href="https://www.ted.com/talks/andrew_connolly_what_s_the_next_window_into_our_universe">Andy Connolly's LSST TED Talk</a>.</li><li><a href="https://confluence.lsstcorp.org/display/LKB/LSST+Key+Numbers">LSST Key Numbers</a>.</li><li><a href="https://arxiv.org/abs/0805.2366">LSST Overview Paper</a>.</li></ul></div><div class="step step-level-1" step="9" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="43200" data-y="0" data-z="0"><h1 id="depth">Depth</h1><h2 id="deepest-ground-based-survey-telescope">Deepest ground-based survey telescope</h2><ul><li>Naked eye: 6 magnitude.</li><li>Single-visit (red): 24.7 magnitude.</li><li>10-year stacked depth (red): 27.5 magnitude.</li><li>30/400 million times fainter than naked eye.</li></ul><p>However...</p><ul><li>Not the deepest <em>telescope</em>.</li><li>Hubble Space Telescope: 31.</li><li>James Webb Space Telescope: 34 magnitude (expected)</li></ul></div><div class="step step-level-1" step="10" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="48000" data-y="0" data-z="0"><h1 id="field-of-view">Field of view</h1><p>Depth isn't everything.</p><ul><li>Humongous FoV: 9.62 degrees <sup>2</sup>.</li><li>40 full moons; roughly a CD held at arm's length.</li><li>JWST, by contrast, is 9.7 arcmin <sup>2</sup>, so roughly
1/3600 of LSST.</li><li>This lets us cover the whole Southern sky in three nights.</li><li>Image by Nate Lust, based on data from the HSC collaboration.</li></ul><img src="images/fov.png" alt="Image by Nate Lust, based on data from the HSC collaboration." height="400px"></img></div><div class="step step-level-1" step="11" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="52800" data-y="0" data-z="0"><h1 id="camera">Camera</h1><ul><li>Focal plane array: 3.2 Gpixels.<ul><li>Nadine Kurita, former Project Manager for Camera, for scale.</li></ul></li><li>189 4K x 4K sensors (roughly 400 4K monitors).</li><li>18 bits per pixel.</li><li>Each exposure 15 seconds.</li><li>Two exposures per visit (to do cosmic-ray/atmospheric transient
rejection, plus a bit of science).</li></ul><img src="images/camera.png" height="400px"></img></div><div class="step step-level-1" step="12" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="57600" data-y="0" data-z="0"><h1 id="lsst-mirror-design"><a href="https://www.lsst.org/about/tel-site/mirror">LSST Mirror Design</a></h1><ul><li><dl><dt>8.4m, but that combines primary and tertiary.</dt><dd><ul><li>Effective collection area equivalent to 5.6m mirror.</li></ul></dd></dl></li><li>Not the largest primary telescope mirror, but...</li><li>The primary/tertiary mirror is the largest monolithic piece of glass
ever fabricated.</li></ul><img src="images/mirror.gif" height="400px"></img><div class="notes"><p>Larger mirrors are generally segmented rather than monolithic.</p></div></div><div class="step step-level-1" step="13" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="62400" data-y="0" data-z="0"><h1 id="cost">Cost</h1><ul><li>Observatory: about $500 million (all numbers in 2013 dollars).</li><li>Camera: about $165 million.</li><li>Primary/tertiary mirror: about $25 million.</li><li>Operations:<ul><li>A little more than a dollar a second.</li><li>On the order of $100,000 a day.</li><li>Roughly $35 million a year.</li></ul></li></ul></div><div class="step step-level-1" step="14" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="67200" data-y="0" data-z="0"><h1 id="site">Site</h1><p><iframe width="1165" height="655" src="https://www.youtube.com/embed/bhuadLB7jvc" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></p></div><div class="step step-level-1" step="15" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="72000" data-y="0" data-z="0"><div class="line-block"><br></br></div></div><div class="step step-level-1" step="16" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="76800" data-y="0" data-z="0"><h1 id="astronomical-status-quo">Astronomical Status Quo</h1><p>Historically, astronomical research has been done with:</p><ul><li><dl><dt>Desktop or laptop computer:</dt><dd><ul><li>Usually pretty beefy by the standards of the day.</li></ul></dd></dl></li><li><dl><dt>Astronomical software:</dt><dd><ul><li>Usually written by the researcher to address a particular
hypothesis.</li><li>Usually written by a single astronomer, rather than a
team of software engineers.</li><li>Maybe written by many astronomers, which is arguably worse.</li></ul></dd></dl></li><li>Downloaded data stored locally.</li></ul></div><div class="step step-level-1" step="17" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="81600" data-y="0" data-z="0"><h1 id="obvious-failure-modes">Obvious Failure Modes</h1><ul><li>Local machine: age, security, IT practices.</li><li>Software: applicability, software engineering.</li><li>Data: scale, backups, DR.</li></ul></div><div class="step step-level-1" step="18" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="86400" data-y="0" data-z="0"><h1 id="data">Data</h1><ul><li>Rights: already extremely broad.<blockquote><ul><li>Roughly half the astronomical community.</li><li>Finding reviewers for the overview paper has been hard.</li></ul></blockquote></li><li>Scale: most will never be directly examined by a human.</li></ul></div><div class="step step-level-1" step="19" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="91200" data-y="0" data-z="0"><h1 id="a-different-way-to-do-astronomy">A Different Way To Do Astronomy</h1><ul><li>The analysis, not the data, is the professionally-valuable part.</li><li>How do we facilitate rapid iteration of analysis?<ul><li>Quickly try a lot of hypotheses and discard unpromising ones.</li><li>Once you have one you like, turn it loose on a lot of data.</li></ul></li></ul></div><div class="step step-level-1" step="20" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="96000" data-y="0" data-z="0"><h1 id="interactive-vs-batch">Interactive vs. Batch</h1><p>We expect that a researcher will use the "interactive notebook aspect of
the LSST Science Platform" (by which we mean JupyterLab, or perhaps its
successors) to perform this iteration.  It is a rapid prototyping tool
with the following characteristics:</p><ul><li>Relatively tiny subset of the data: a few terabytes, probably less.</li><li>The <em>real</em> analysis will be submitted to a batch system to work on
petabyte-scale data.</li><li>We don't (and can't) know what subset we want in advance.</li></ul></div><div class="step step-level-1" step="21" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="100800" data-y="0" data-z="0"><h1 id="what-does-this-imply">What does this imply?</h1><ul><li>It's not really about speed of data access or computation.</li><li>Access to completely arbitrary subsets of the data, however, is
<em>absolutely crucial</em>.</li><li>Bring your code to the data, not the other way around.</li></ul></div><div class="step step-level-1" step="22" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="105600" data-y="0" data-z="0"><h1 id="what-do-we-want">What Do We Want?</h1><p>Let's imagine a better world:</p><ul><li>You don't need to spend hours-to-weeks setting up the software
environment.</li><li>In fact, all that's needed for analysis is a web browser.  Compute and
data storage happen somewhere else.</li><li>You have a single login to manage your access to the environment.</li><li>You don't need to pick a data subset that will fit on your laptop or
your desktop NAS.</li><li>The analysis is running on professionally-maintained machines in a
real datacenter somewhere that it isn't your problem.</li></ul></div><div class="step step-level-1" step="23" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="110400" data-y="0" data-z="0"><h1 id="community-acceptance">Community Acceptance</h1><p>The trickiest design goal is that we cannot make any user's life
significantly worse than the status quo.</p><p>Obviously the current system isn't ideal:</p><ul><li>Large, complex, bespoke analysis stack.</li><li>Hugely complicated installation and configuration.</li><li>Enormous amounts of technical debt.</li></ul><p>But...it also gets the job done.  The analysis software encodes
literally hundreds, perhaps thousands, of astronomer-years of work on
difficult problems.  It is inherently complex.</p><p>We have to please several different groups of users.</p></div><div class="step step-level-1" step="24" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="115200" data-y="0" data-z="0"><h1 id="user-community">User Community</h1><h2 id="analysis-pipeline-consumers">Analysis Pipeline Consumers</h2><p>We have this one covered.  If you want to use the existing toolset to
analyze collected data, and you're not coming to the project with a lot
of prior experience or actively developing the pipeline software, we're
delivering a far superior way to get your work done than the prior art.</p></div><div class="step step-level-1" step="25" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="120000" data-y="0" data-z="0"><h1 id="id3">User Community</h1><h2 id="analysis-pipeline-developers">Analysis Pipeline Developers</h2><p>The LSST stack is big.  No one works on the whole thing.  The way it's
developed is that someone takes a version (either a release version,
approximately every 6 months, or a weekly build) and works on their own
little corner of it in a conda or pip environment.  We must support
that.</p></div><div class="step step-level-1" step="26" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="124800" data-y="0" data-z="0"><h1 id="id4">User Community</h1><h2 id="established-astronomers">Established Astronomers</h2><p>The people who have tenure and bring in the grants already have a
workflow that works well for them.  Sure, it's based on FORTRAN IV and
FITS files, but they've gotten really, really good at it.</p><p>In practice: you need a Terminal window that gives you shell access to
something that looks like a Unix system.  We mimic a system on which you
have an unprivileged account, which is very familiar to academic users.</p><p>There is something of an Uncanny Valley problem here.</p></div><div class="step step-level-1" step="27" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="129600" data-y="0" data-z="0"><h1 id="id5">User Community</h1><h2 id="security-generally-operational-support">Security; generally, Operational Support</h2><img src="images/Dumpsterfire.gif" alt="Image composition by Abbey Yacoe." height="300px"></img><p>It's a fair cop, but if if we make it look like an existing multi-user
system, where the user doesn't have <tt>root</tt> or <tt>sudo</tt> within the
container, and has write access only to <tt>${HOME}</tt> and scratch space
but not the OS, and furthermore we show that we can completely
characterize the container's contents, it's a much easier sell.</p><ul><li>Image by Abbey Yacoe.</li></ul></div><div class="step step-level-1" step="28" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="134400" data-y="0" data-z="0"><h1 id="the-big-reveal">The Big Reveal</h1><p>(Not actually a surprise to anyone here.)</p><h2 id="kubernetes-jupyterhub-jupyterlab">Kubernetes + JupyterHub + JupyterLab</h2><ul><li>Kubernetes: it clearly won.  Google, Amazon, and Azure all offer
managed Kubernetes infrastructure.</li><li>JupyterLab: the UX is much better than the classic notebook.
Multiple panes within a single browser tab, including terminal
sessions, is a tremendous feature, giving users basically an IDE.</li><li>JupyterHub: the obvious choice for access control and resource
allocation brokering.  Authenticator and Spawner subclasses let us
do some really nifty things, which you will see.</li></ul><p>Banek <em>et al.</em>, ADASS 2019: <a href="https://arxiv.org/abs/1911.06404">Why is the LSST Science Platform built on
Kubernetes?</a></p></div><div class="step step-level-1" step="29" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="139200" data-y="0" data-z="0"><h1 id="abstraction-and-layering">Abstraction and Layering</h1><ul><li>Virtualization lets you stop caring about the specifics of your
hardware.</li><li>Containerization lets you stop caring about managing the
OS/distribution layer.</li><li>Kubernetes lets you stop caring about managing the inter-component
networking of your application and container lifecycle management.</li></ul></div><div class="step step-level-1" step="30" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="144000" data-y="0" data-z="0"><h1 id="the-long-bet">The Long Bet</h1><p>Kubernetes will save astronomy.</p><ul><li>It's the first time we've had a functional abstraction layer that
allows you to specify scalable architectural designs.</li><li>This lets you create complex multicomponent applications that will run
on any suitable cluster, with built-in lifecycle management.</li><li>And because it's modular, you can use best-practice patterns for all
the infrastructure and only <em>really</em> care about managing the analysis
stack that is your actual application.</li></ul></div><div class="step step-level-1" step="31" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="148800" data-y="0" data-z="0"><h1 id="modularity">Modularity</h1><ul><li>Separate plumbing from application.</li><li>Provide a clear way to replace the value-added part (for us: the LSST
Science Pipeline) with your own payload.</li><li>Retain the robust infrastructure with component lifecycle management
and automated resource allocation.</li></ul><p>This lets you both have your cake and eat it.  You get to use whatever
insanely complex analysis framework you want wrapped inside a
general-purpose, self-healing application architecture.</p></div><div class="step step-level-1" step="32" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="153600" data-y="0" data-z="0"><h1 id="presenting-the-analysis-component">Presenting the Analysis Component</h1><p>Replacing the payload is a matter of replacing the JupyterLab container
that is spawned for the user.  All you need is:</p><ul><li>A container that will start a JupyterLab server.</li><li><a href="https://github.com/lsst-sqre/jupyterlabdemo/blob/master/jupyterlab/lsstlaunch.bash">Some way</a> to wrap your analysis pipeline up as a Jupyter kernel.</li></ul><p>I would be flabbergasted if this approach were not portable to other
physical sciences and very possibly to other (and very general) analytic
problem spaces.</p><img src="images/kernel.png" height="300px"></img></div><div class="step step-level-1" step="33" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="158400" data-y="0" data-z="0"><h1 id="parallelization">Parallelization</h1><ul><li>There should be some way for users to run jobs larger than a single
container, but not real-batch-system sized (dozens of CPU cores, not
thousands).<blockquote><ul><li>We use Dask.</li><li>Could use Vaex.</li><li>Looking into Argo Workflows for pipelines and headless notebook
execution (very handy for CI).</li></ul></blockquote></li><li>You also need a reasonable interface to your real at-scale workflow
system.</li><li>By the end of the survey in 2032, things that are now "real batch"
will be totally feasible in a Dask-like environment.  Plan for that.</li></ul></div><div class="step step-level-1" step="34" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="163200" data-y="0" data-z="0"><h1 id="resource-management">Resource Management</h1><ul><li>The Hub needs Kubernetes cluster-level privileges for cross-namespace
games.</li><li>Spawn each user into its own namespace, with a quota restricting CPU
and memory available.<blockquote><ul><li>Could also use to regulate access to GPUs and other enumerated
resources.</li></ul></blockquote></li><li>Hierarchical namespaces, or at least regex-based namespace
restrictions, would make this a lot easier in a shared-tenancy
environment.</li><li>Our general assumption thus far has been that the LSP is the only
tenant in the cluster.</li></ul></div><div class="step step-level-1" step="35" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="168000" data-y="0" data-z="0"><h1 id="scaling">Scaling</h1><p>Step one: Add more nodes to your cluster.  (Or take some away.)</p><ul><li>In a public cloud, this is really, really easy.  Perhaps even
automated.</li></ul><p>Step two: Change the replica counts in your deployments.</p><ul><li>You can turn this into a closed-loop automated system by monitoring
your load too.</li></ul><p>There is no step three.</p></div><div class="step step-level-1" step="36" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="172800" data-y="0" data-z="0"><h1 id="contributing">Contributing</h1><p>The Jupyter community is awesome.</p><p>JupyterLab has stabilized a lot.  1.0.x is current, and 2.0 is aimed at
New Year 2020.</p><ul><li>Sometimes underdocumented.</li><li>Documentation is not very discoverable.</li><li>Everyone is busy working on their own projects.</li><li>The best way to proceed is to implement something and then wait for
the gasps of horror from the people who <em>are</em> experts, then do what
they say.</li></ul></div><div class="step step-level-1" step="37" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="177600" data-y="0" data-z="0"><div class="line-block"><br></br></div></div><div class="step step-level-1" step="38" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="182400" data-y="0" data-z="0"><h1 id="lsst-jupyterlab-implementation">LSST JupyterLab Implementation</h1><h2 id="id6">Overview</h2><p><a href="https://sqr-018.lsst.io/">SQR-018</a> describes the architecture.</p><p>The complete implementation is available at <a href="https://github.com/lsst-sqre/jupyterlabdemo">GitHub</a>.</p><img src="images/jupyterlab_sp.png" height="400px"></img></div><div class="step step-level-1" step="39" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="187200" data-y="0" data-z="0"><h1 id="deployment">Deployment</h1><p>Just use Helm</p><ul><li>We had an overly complex hand-rolled deployment framework.</li><li>We also tried Terraform.</li><li>Christine Banek (<a href="mailto:cbanek@lsst.org">cbanek@lsst.org</a>) put together Helm Charts and it's
the easiest way to go.</li><li>Probably, you can use <a href="https://github.com/jupyterhub/zero-to-jupyterhub-k8s/">Zero to Jupyterhub</a> instead.</li></ul></div><div class="step step-level-1" step="40" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="192000" data-y="0" data-z="0"><h1 id="problem-1-authentication">Problem 1: Authentication</h1><p>Authentication is annoying and hard.  Let's outsource it.</p><ul><li>OAuth2 is a thing, and JupyterHub supports it well; we can do GitHub
or CILogon with the NCSA ID provider (adding more is straightforward,
and NCSA lets us associate external accounts).</li><li>However, we don't want to make each LSST Science Platform component
implement its own auth.<blockquote><ul><li>OAuth2 Proxy implementing JWT.  Not outside-of-LSST-portable at
the moment; passes auth information around inside HTTP headers.</li><li>Expiry becomes trickier.</li></ul></blockquote></li><li>We need authorization as well.  Even when we know who you are, you
might not get to use the system</li></ul><p><a href="images/screenshots/cilogon.png">[cilogon_screenshot]</a></p></div><div class="step step-level-1" step="41" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="196800" data-y="0" data-z="0"><h1 id="problem-2-authorization">Problem 2: Authorization</h1><p>How do we restrict beyond "has a GitHub/NCSA account"?</p><p>Both have concepts of group memberships.</p><ul><li>OAuth2 scopes allow us to attach capabilities to tokens; for instance,
"enumerate a user's groups."  That's what you need to determine if you
are in the LSST group.</li><li>If using JWT, pack that info into JWT or have a secondary call to
figure it out.</li></ul><p><a href="images/screenshots/denylist.png">[auth_screenshot]</a></p></div><div class="step step-level-1" step="42" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="201600" data-y="0" data-z="0"><h1 id="problem-3-global-user-consistency">Problem 3: Global User Consistency</h1><p>GitHub's user account ID fits into a 32-bit value.  Each GitHub
Organization also has an ID.  There are our UID/GID maps.</p><p>CILogon + NCSA IDP does something similar.</p><p>Now you have globally consistent users and groups.</p><p><a href="images/screenshots/uid-gids.png">[uid_screenshot]</a></p></div><div class="step step-level-1" step="43" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="206400" data-y="0" data-z="0"><h1 id="problem-4-persistent-storage">Problem 4: Persistent Storage</h1><p>We have globally unique UIDs and GIDs.</p><ul><li>We mount <tt>/home</tt> and whatever other filesystems we want.<blockquote><ul><li>I built a helper method to read this from a document at Lab spawn
time for ease of modification.</li></ul></blockquote></li><li>Data access and sharing immediately collapses to the long-solved
problem of Unix filesystem access.</li><li>We use NFS v4, because it's easy.<ul><li>We point to an external NFS server, but you can stand one up within
Kubernetes if you prefer.</li><li>Whatever we eventually pick, it will be exposed as a POSIX
filesystem to our users.</li></ul></li></ul><p><a href="images/screenshots/filesystem.png">[filesystem_screenshot]</a></p></div><div class="step step-level-1" step="44" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="211200" data-y="0" data-z="0"><h1 id="problem-5-user-access-restriction">Problem 5: User Access Restriction</h1><p>Don't give your users <tt>sudo</tt>.  Don't even give them passwords.</p><p>You already have globally-consistent UID and GIDs.  Use a semiprivileged
user to provision user with correct name/UID/GIDs via <tt>sudo</tt> at
container startup.  Start Jupyterlab as that user.</p><p>You're done.</p><p>Users can still override bits of the stack with <tt>pip install --user</tt>.</p><ul><li>Put something on the options form that lets the user clear
<tt>$HOME/.local</tt>.  Trust me on this.</li></ul><p><a href="images/screenshots/nosudo.png">[sudo_screenshot]</a></p></div><div class="step step-level-1" step="45" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="216000" data-y="0" data-z="0"><h1 id="problem-6-user-resource-restriction">Problem 6: User Resource Restriction</h1><p>If you spawn users into individual namespaces:</p><ul><li>Quota the namespaces and let Kubernetes do the enforcement.</li><li>A document-driven quota manager can let you do different quotas by
user or group.</li></ul><p><a href="images/screenshots/namespace_quota.png">[quota_screenshot]</a></p></div><div class="step step-level-1" step="46" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="220800" data-y="0" data-z="0"><h1 id="problem-7-auditability-and-maintainability">Problem 7: Auditability and Maintainability</h1><p>It's a container.  You know how you built it (at least if you use
particular package versions, not <tt>latest</tt>).  It's repeatable and
immutable.  Have a bleeding-edge build, that floats, and an
occasionally-updated-from-that version that pins all OS-level,
Python-level, and JupyterLab-Extension-level components.</p><p>We look for regressions in the stack by creating an <a href="https://github.com/lsst-sqre/jupyterlabdemo/blob/master/jupyterhub/sample_configs/github/20-spawner.py">options form</a> that
scans our repository and presents a menu of recent builds.  This also
allows users to choose their risk tolerance.</p><p><a href="images/screenshots/options.png">[options_screenshot]</a></p></div><div class="step step-level-1" step="47" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="225600" data-y="0" data-z="0"><h1 id="problem-8-startup-time-and-user-frustration">Problem 8: Startup Time and User Frustration</h1><p>Our images are huge and take on the order of 15 minutes to pull.</p><ul><li>"So don't do that."</li><li>Unless your analysis stack is inherently gargantuan...</li><li>...so we pre-pull them.</li></ul><p>Within, say, an hour and a half of building (which is usually in the
middle of the night) each image is available on each node and therefore
starts quickly.</p><p><a href="images/screenshots/prepuller.png">[prepuller_screenshot]</a></p></div><div class="step step-level-1" step="48" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="230400" data-y="0" data-z="0"><h1 id="jupyterlab-resources">JupyterLab Resources</h1><ul><li><a href="https://github.com/jupyterhub/zero-to-jupyterhub-k8s/">Zero To JupyterHub</a>.</li><li><a href="https://gitter.im/jupyterlab/jupyterlab">JupyterLab (and Hub) Gitter</a>.</li><li><a href="https://github.com/lsst-sqre/jupyterlabdemo">LSST JupyterLab Implementation</a>.</li><li><a href="https://arxiv.org/abs/1911.06404">Why is the LSST Science Platform built on Kubernetes?</a></li></ul></div><div class="step step-level-1" step="49" data-rotate-x="0" data-rotate-y="0" data-rotate-z="0" data-scale="1" data-x="235200" data-y="0" data-z="0"><img src="images/screenshot.png" height="768px"></img></div></div><div id="hovercraft-help"><table><tr><th>Space</th><td>Forward</td></tr><tr><th>Right, Down, Page Down</th><td>Next slide</td></tr><tr><th>Left, Up, Page Up</th><td>Previous slide</td></tr><tr><th>G</th><td>Go to slide number</td></tr><tr><th>P</th><td>Open presenter console</td></tr><tr><th>H</th><td>Toggle this help</td></tr></table></div><script type="text/javascript" src="js/impress.js"></script><script type="text/javascript" src="js/impressConsole.js"></script><script type="text/javascript" src="js/hovercraft.js"></script></body></html>